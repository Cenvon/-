1.无监督学习的类型
    1>数据集变换
        数据集的无监督变换时创造数据新的表示的算法，与数据的原始表示相比，新的表示可能
        更容易被人或其他机器学习算法所理解。
    2>聚类
        聚类算法将数据划分成不同的组，每组包含相似的物象

2.无监督学习的挑战
    一个主要挑战就是评估算法是否学到了有用的东西。

3.预处理与缩放
    以下4种缩放方法：
        1.StandardScaler：确保每个特征平均值为0方差为1，使所有特征处于同一量级
        2.RobustScaler：与前者类似，不过使用的是中位数和四分位数来代替均值方差
        3.MinMaxScaler：移动数据，使所有特征都刚好位于0和1之间
        4.Normalizer：每队各数据点进行缩放，使得特征向量的欧式长度为1

    所有的预处理类都具有相同的接口，都包含fit和transform方法。

    通常来说，你想要在某个数据集上fit一个模型，然后再将其transform。这是一个非常常见的
    任务，通常可以用比先调用fit在调用transform更高效的方法来计算。对于这个种使用场景，
    所有具有transform方法的模型也都具有一个fit_transform方法
    x=scale.fit(x).transform(X)
    x=sacle.fit_transform(x)

4.降维、特征提取与流形学习
    1>主成分分析(PCA)：
        PCA是一种旋转数据集的方法，旋转后的特征在统计上不相关。
        mglearn.plots.plot_pca_illustration() #P103
        PCA另一个应用是特征提取，其背后的思想是，可以找到一种数据表示，比给定的原始表示更适合分析。
