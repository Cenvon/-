"""
虽然深度学习在许多机器学习应用中都有巨大潜力，但深度学习算法往往经过精确调整，只适用于
特定的使用场景。这里讨论一些相对简单的方法，即用于分类和回归的多层感知机(multilayer 
perceptron,MLP),它可以作为研究更复杂的深度学习方法的起点。MLP也被称为(普通)前馈神经
网络，有时也简称神经网络。

1.神经网络模型
    MLP可以被视为广义的线性模型，执行多层处理后得出结论。
        h[0]=tanh(w[0,0]*x[0]+w[1,0]*x[1]+w[2,0]*x[2]+b[0])
        h[1]=tanh(w[0,0]*x[0]+w[1,0]*x[1]+w[2,0]*x[2]+b[1])
        h[2]=tanh(w[0,0]*x[0]+w[1,0]*x[1]+w[2,0]*x[2]+b[2])
        y=v[0]*h[0]+v[1]*h[1]+v[2]*h[2]+b
    其中w是输入x和隐藏层h之间的权重，v是隐层h与输出y之间的权重。权重w和v要从数据中学习
    得到，x是输入特征，h是计算的中间结果。

2.调参
    神经网络的决策边界完全是非线性的，但相对平滑。我们用到了solver='lbfgs'，这一点稍后
    会讲到。默认的非线性是relu
    MLPClassifier中调节L2惩罚的参数是alpha，它的默认值很小(弱正则化)。
3.优缺点和参数
    *优点：主要优点之一是能够获得大量数据中包含的信息，并构建无比复杂的模型。给定足够计
    算时间以及数据，并且仔细调参，神经网络可以打败其他机器学习算法(包括分类和回归)。
    *缺点：功能强大的大型神经网络需要很长的训练时间。
    *参数：alpha：增大alpha来增强正则化，这可以提高泛化性能
          solver：如何学习模型或用来学习参数的算法。默认是"adam"对数据缩放相当敏感，
          "lbfgs"其鲁棒性相当好，但大数据或大模型时耗时较长，"sgd"深度学习研究用。



"""